{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import blackjack_engine\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from blackjack_api_example.py\n",
    "def padarray(A, size):\n",
    "    if len(A) == 0:\n",
    "        A = ['']\n",
    "    t = size - len(A)\n",
    "    arr = np.pad(A, pad_width=(0, t), mode='empty')\n",
    "    \n",
    "    return arr.astype('<U32')\n",
    "\n",
    "def player_bot(hand):\n",
    "    \"\"\" makes random choice, or makes decisions using neural net etc\"\"\"\n",
    "    # decision making code goes here\n",
    "    return random.choice(['hit', 'stay']) \n",
    "\n",
    "def play_blackjack_game():\n",
    "    # initialize a game with shuffled deck and hands dealt to dealer and player:\n",
    "    game = blackjack_engine.BlackjackGame()\n",
    "    moves = []\n",
    "    #game_states = []\n",
    "    dealer_cards = []\n",
    "    player_hands = []\n",
    "    game_results = []\n",
    "    if game.is_finished == False: # if nobody got dealt a blackjack, loop through decisions\n",
    "        while True: \n",
    "            player_hand = game.player_hands[0].cards[:]\n",
    "            dealer_card = game.dealer_hand.cards[0]\n",
    "            #game_state_row = {'player_hand':player_hand,'dealer_card':dealer_card}\n",
    "            #game_state_row = [player_hand, dealer_card]\n",
    "            player_hands.append(player_hand)\n",
    "            dealer_cards.append(dealer_card)\n",
    "            hit_or_stay = player_bot(game.player_hands)\n",
    "            moves.append(hit_or_stay)\n",
    "            game.player_move(hit_or_stay)\n",
    "\n",
    "            if not game.is_finished:\n",
    "                continue # game is not finished so continue loop\n",
    "            if game.is_finished:\n",
    "                [game_results.append(game.result) for game_result in np.arange(len(moves))]\n",
    "                break # game is finished so exit loop\n",
    "    return player_hands, dealer_cards, moves, game_results\n",
    "\n",
    "# implement a training set generation routine: give the API random actions and see how games turn out\n",
    "def build_training_set(n_pts):\n",
    "    '''\n",
    "    state_of_play is an n x m array of values where n is the number of data points, and m is the max number of features in a hand \n",
    "    y is an n x 1 array, where n is the number of data points (number of times the player drew a card, basically) \n",
    "    '''\n",
    "    all_player_hands = []\n",
    "    all_dealer_cards = []\n",
    "    all_moves = []\n",
    "    all_game_results = []\n",
    "\n",
    "    for pt in np.linspace(0,n_pts,n_pts+1):\n",
    "        [player_hands, dealer_cards, moves,game_results] = play_blackjack_game()\n",
    "        all_player_hands.append(player_hands)\n",
    "        all_dealer_cards.append(dealer_cards)\n",
    "        all_moves.append(moves)\n",
    "        all_game_results.append(game_results)\n",
    "    return all_player_hands, all_dealer_cards, all_moves, all_game_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Q', '2'], ['Q', '2', '4']],\n",
       " [['4', '6'], ['4', '6', '5'], ['4', '6', '5', 'A']],\n",
       " [['7', '7']],\n",
       " [],\n",
       " [['Q', '10']],\n",
       " [['6', '8']],\n",
       " [['Q', '5']],\n",
       " [['10', '8']],\n",
       " [['A', 'A']],\n",
       " [['7', 'K']],\n",
       " [['3', '6']]]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[all_player_hands, all_dealer_cards, all_moves, all_game_results] = build_training_set(10)\n",
    "all_player_hands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hit', 'hit'],\n",
       " ['hit', 'hit', 'hit'],\n",
       " ['stay'],\n",
       " [],\n",
       " ['hit'],\n",
       " ['hit'],\n",
       " ['stay'],\n",
       " ['stay'],\n",
       " ['stay'],\n",
       " ['stay'],\n",
       " ['stay']]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Q', '2'], ['Q', '2', '4']],\n",
       " [['4', '6'], ['4', '6', '5'], ['4', '6', '5', 'A']],\n",
       " [['7', '7']],\n",
       " [],\n",
       " [['Q', '10']],\n",
       " [['6', '8']],\n",
       " [['Q', '5']],\n",
       " [['10', '8']],\n",
       " [['A', 'A']],\n",
       " [['7', 'K']],\n",
       " [['3', '6']]]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the data such that each row represents a decision instance\n",
    "flat_moves = list(np.concatenate(all_moves).flat)\n",
    "#flat_player_hands = list(np.concatenate(all_player_hands).flat)\n",
    "flat_game_results = list(np.concatenate(all_game_results).flat)\n",
    "all_player_hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build the input and output datasets\n",
    "# input: game_states (padded), results \n",
    "# output: decision (hit or stay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network on the previously generated data\n",
    "def build_model(X,y):\n",
    "    input_shape = np.shape(X)\n",
    "    output_shape = np.shape(y) \n",
    "    # use a simple sequential dense model to predict which actions will result in a win\n",
    "    return model\n",
    "\n",
    "def train_model(untrained_model,training_data):\n",
    "    training_data = [X_train, y_train, X_test, y_test]\n",
    "    \n",
    "    return trained_network\n",
    "\n",
    "def use_model_to_make_decision(trained_model,state_of_play):\n",
    "\n",
    "    decision = trained_model.predict(state_of_play)\n",
    "    while game_is_still_in_play:\n",
    "        state_of_play = play_blackjack_hand(state_of_play,decision)\n",
    "        game_is_still_in_play = check_result(state_of_play)\n",
    "    return state_of_play\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'player_hand': ['6', 'K'], 'dealer_card': '8'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_game_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.0, -1.0, -1.0, -1.0, -1.0, 0.0, -1.0, -1.0, -1.0, 0.0, 0.0, -1.0, -1.0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_game_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-keras-gpu]",
   "language": "python",
   "name": "conda-env-.conda-keras-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
